import os
import numpy as np
from PIL import Image
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pickle
import warnings
warnings.filterwarnings('ignore')

IMG_DIR = "img"
MODEL_PATH = "lung_model.pkl"
SCALER_PATH = "scaler.pkl"

def extract_features_from_image(image_path):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ 13 Ù…ÙŠØ²Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©"""
    img = Image.open(image_path).convert('L')
    
    # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…
    img = img.resize((224, 224))
    img_array = np.array(img)
    
    features = []
    
    # 1-4: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    features.append(np.mean(img_array))
    features.append(np.std(img_array))
    features.append(np.min(img_array))
    features.append(np.max(img_array))
    
    # 5-12: Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø±Ø¨Ø§Ø¹
    h, w = img_array.shape
    quadrants = [
        img_array[:h//2, :w//2],
        img_array[:h//2, w//2:],
        img_array[h//2:, :w//2],
        img_array[h//2:, w//2:]
    ]
    
    for quad in quadrants:
        features.append(np.mean(quad))
        features.append(np.std(quad))
    
    # 13: Ø§Ù„Ø­Ø§ÙØ§Øª
    edges = np.abs(np.diff(img_array, axis=0)).mean() + np.abs(np.diff(img_array, axis=1)).mean()
    features.append(edges)
    
    return np.array(features)

def train():
    print("\n=== ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ===\n")
    
    if not os.path.exists(IMG_DIR):
        print(f"Ø®Ø·Ø£: Ù…Ø¬Ù„Ø¯ {IMG_DIR} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return
    
    # Ø¬Ù…Ø¹ Ø§Ù„ØµÙˆØ±
    images = []
    labels = []
    
    for filename in os.listdir(IMG_DIR):
        filepath = os.path.join(IMG_DIR, filename)
        if os.path.isfile(filepath):
            try:
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø©
                if "normal" in filename.lower() or "healthy" in filename.lower():
                    label = 0
                elif "cancer" in filename.lower() or "tumor" in filename.lower():
                    label = 1
                else:
                    continue
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                features = extract_features_from_image(filepath)
                images.append(features)
                labels.append(label)
                print(f"âœ“ {filename} -> {'Ø³Ù„ÙŠÙ…Ø©' if label == 0 else 'Ø³Ø±Ø·Ø§Ù†'}")
            except Exception as e:
                print(f"âœ— Ø®Ø·Ø£ ÙÙŠ {filename}: {e}")
    
    if len(images) == 0:
        print("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ± Ù„Ù„ØªØ¯Ø±ÙŠØ¨!")
        return
    
    X = np.array(images)
    y = np.array(labels)
    
    print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
    print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙˆØ±: {len(X)}")
    print(f"ØµÙˆØ± Ø³Ù„ÙŠÙ…Ø©: {np.sum(y == 0)}")
    print(f"ØµÙˆØ± Ø³Ø±Ø·Ø§Ù†: {np.sum(y == 1)}")
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    print("\nğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=15,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train_scaled, y_train)
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    train_score = model.score(X_train_scaled, y_train)
    test_score = model.score(X_test_scaled, y_test)
    
    print(f"\nâœ“ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨!")
    print(f"Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train_score*100:.2f}%")
    print(f"Ø¯Ù‚Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {test_score*100:.2f}%")
    
    # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(model, f)
    
    with open(SCALER_PATH, 'wb') as f:
        pickle.dump(scaler, f)
    
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ {MODEL_PATH}")
    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø© ÙÙŠ {SCALER_PATH}")

if __name__ == "__main__":
    train()
