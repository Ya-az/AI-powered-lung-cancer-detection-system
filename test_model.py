"""
Ø³ÙƒØ±ÙŠØ¨Øª Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØªÙ‚ÙŠÙŠÙ… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø±Ø¦Ø©
ÙŠØ¹Ø±Ø¶ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³ØŒ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙØŒ ÙˆÙ…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix, 
    classification_report, 
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_curve,
    auc
)
import warnings
warnings.filterwarnings('ignore')

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ PyTorch
try:
    import torch
    import torch.nn as nn
    from torchvision import transforms
    from PIL import Image
    PYTORCH_AVAILABLE = True
except ImportError:
    PYTORCH_AVAILABLE = False
    print("âš ï¸ PyTorch ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Scikit-learn ÙÙ‚Ø·.")

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Scikit-learn
try:
    import pickle
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ Scikit-learn ØºÙŠØ± Ù…ØªÙˆÙØ±.")

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
try:
    from config import *
except ImportError:
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† config.py Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    IMG_DIR = "img"
    MODEL_PATH = "lung_model.pth"
    MODEL_PATH_SKLEARN = "lung_model.pkl"
    SCALER_PATH = "scaler.pkl"
    IMAGE_SIZE = (224, 224)
    CLASS_NAMES_AR = ["Ø³Ù„ÙŠÙ…Ø©", "Ø³Ø±Ø·Ø§Ù†"]

# ==================== PyTorch Model ====================
if PYTORCH_AVAILABLE:
    class LungClassifier(nn.Module):
        """Ù†Ù…ÙˆØ°Ø¬ CNN"""
        def __init__(self):
            super(LungClassifier, self).__init__()
            self.features = nn.Sequential(
                nn.Conv2d(3, 32, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(32, 64, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(64, 128, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(128, 256, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
            )
            
            self.classifier = nn.Sequential(
                nn.Linear(256 * 14 * 14, 512),
                nn.ReLU(inplace=True),
                nn.Dropout(0.5),
                nn.Linear(512, 256),
                nn.ReLU(inplace=True),
                nn.Dropout(0.5),
                nn.Linear(256, 2)
            )
        
        def forward(self, x):
            x = self.features(x)
            x = x.view(x.size(0), -1)
            x = self.classifier(x)
            return x

# ==================== Scikit-learn Functions ====================
def extract_features_sklearn(image_path):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Scikit-learn"""
    from PIL import Image
    from scipy.ndimage import label
    
    img = Image.open(image_path).convert('L')
    img = img.resize((224, 224))
    arr = np.array(img, dtype=np.float32)
    
    features = []
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©
    features.append(np.mean(arr))
    features.append(np.std(arr))
    features.append(np.min(arr))
    features.append(np.max(arr))
    
    # Percentiles
    features.extend([np.percentile(arr, 25), np.percentile(arr, 50), 
                     np.percentile(arr, 75), np.percentile(arr, 90)])
    
    # ÙƒØ´Ù Ø§Ù„Ø¨Ù‚Ø¹ Ø§Ù„Ø¯Ø§ÙƒÙ†Ø©
    thresh = np.percentile(arr, 30)
    dark = arr < thresh
    features.append(np.sum(dark))
    features.append(np.sum(dark) / arr.size)
    
    # Connected components
    try:
        labeled, num = label(dark)
        features.append(num)
        if num > 0:
            sizes = np.bincount(labeled.ravel())
            features.append(np.mean(sizes[1:]))
            features.append(np.max(sizes[1:]))
        else:
            features.extend([0, 0])
    except:
        features.extend([0, 0, 0])
    
    # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
    edges_x = np.abs(np.diff(arr, axis=0)).mean()
    edges_y = np.abs(np.diff(arr, axis=1)).mean()
    features.extend([edges_x, edges_y, edges_x + edges_y])
    
    # Histogram
    hist, _ = np.histogram(arr, bins=4, range=(0, 256))
    hist = hist / hist.sum()
    features.extend(hist)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±ÙƒØ²
    center = arr[50:174, 50:174].mean()
    features.append(center)
    features.append((arr[50:174, 50:174] < thresh).sum())
    
    # Variance
    features.append(np.var(arr - arr.mean()))
    features.append(np.sum(arr < np.percentile(arr, 20)))
    
    return np.array(features)

# ==================== Testing Functions ====================
def load_test_data():
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    if not os.path.exists(IMG_DIR):
        print(f"âŒ Ù…Ø¬Ù„Ø¯ {IMG_DIR} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return None, None, None
    
    images_path = []
    labels = []
    
    for filename in sorted(os.listdir(IMG_DIR)):
        filepath = os.path.join(IMG_DIR, filename)
        if not os.path.isfile(filepath):
            continue
        
        if "normal" in filename.lower():
            label = 0
        elif "cancer" in filename.lower():
            label = 1
        else:
            continue
        
        images_path.append(filepath)
        labels.append(label)
    
    print(f"âœ“ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(images_path)} ØµÙˆØ±Ø©")
    print(f"  - Ø³Ù„ÙŠÙ…Ø©: {labels.count(0)}")
    print(f"  - Ø³Ø±Ø·Ø§Ù†: {labels.count(1)}")
    
    return images_path, np.array(labels), None

def test_pytorch_model(images_path, true_labels):
    """Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ PyTorch"""
    if not PYTORCH_AVAILABLE:
        print("âš ï¸ PyTorch ØºÙŠØ± Ù…ØªÙˆÙØ±")
        return None, None
    
    if not os.path.exists(MODEL_PATH):
        print(f"âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {MODEL_PATH} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        return None, None
    
    print("\n" + "="*60)
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ PyTorch")
    print("="*60)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    device = torch.device("cpu")
    model = LungClassifier().to(device)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.eval()
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤
    transform = transforms.Compose([
        transforms.Resize(IMAGE_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    predictions = []
    probabilities = []
    
    print("\nğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤...")
    for img_path in images_path:
        image = Image.open(img_path).convert('RGB')
        img_tensor = transform(image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred = torch.argmax(probs, dim=1).item()
            
            predictions.append(pred)
            probabilities.append(probs[0].cpu().numpy())
    
    predictions = np.array(predictions)
    probabilities = np.array(probabilities)
    
    return predictions, probabilities

def test_sklearn_model(images_path, true_labels):
    """Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Scikit-learn"""
    if not SKLEARN_AVAILABLE:
        print("âš ï¸ Scikit-learn ØºÙŠØ± Ù…ØªÙˆÙØ±")
        return None, None
    
    model_path = MODEL_PATH_SKLEARN if os.path.exists(MODEL_PATH_SKLEARN) else "lung_model.pkl"
    scaler_path = SCALER_PATH if os.path.exists(SCALER_PATH) else "scaler.pkl"
    
    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        print(f"âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Scaler ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        return None, None
    
    print("\n" + "="*60)
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Scikit-learn")
    print("="*60)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    with open(scaler_path, 'rb') as f:
        scaler = pickle.load(f)
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
    print("\nğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª...")
    features_list = []
    for img_path in images_path:
        features = extract_features_sklearn(img_path)
        features_list.append(features)
    
    X = np.array(features_list)
    X_scaled = scaler.transform(X)
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤
    predictions = model.predict(X_scaled)
    probabilities = model.predict_proba(X_scaled)
    
    return predictions, probabilities

def plot_confusion_matrix(y_true, y_pred, title="Confusion Matrix"):
    """Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³"""
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=CLASS_NAMES_AR, 
                yticklabels=CLASS_NAMES_AR,
                cbar_kws={'label': 'Count'})
    
    plt.title(title, fontsize=16, fontweight='bold', pad=20)
    plt.ylabel('Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©', fontsize=12, fontweight='bold')
    plt.xlabel('Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©', fontsize=12, fontweight='bold')
    plt.tight_layout()
    
    return cm

def plot_metrics(y_true, y_pred, y_proba, model_name):
    """Ø±Ø³Ù… Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ {model_name}', fontsize=16, fontweight='bold')
    
    # 1. Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],
                xticklabels=CLASS_NAMES_AR, yticklabels=CLASS_NAMES_AR)
    axes[0, 0].set_title('Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³', fontweight='bold')
    axes[0, 0].set_ylabel('Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©')
    axes[0, 0].set_xlabel('Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©')
    
    # 2. Performance Metrics Bar Chart
    metrics = {
        'Accuracy': accuracy_score(y_true, y_pred),
        'Precision': precision_score(y_true, y_pred, average='weighted'),
        'Recall': recall_score(y_true, y_pred, average='weighted'),
        'F1-Score': f1_score(y_true, y_pred, average='weighted')
    }
    
    bars = axes[0, 1].bar(metrics.keys(), metrics.values(), 
                          color=['#28a745', '#dc3545', '#ffc107', '#17a2b8'],
                          alpha=0.7, edgecolor='black', linewidth=2)
    axes[0, 1].set_ylim(0, 1.1)
    axes[0, 1].set_title('Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡', fontweight='bold')
    axes[0, 1].set_ylabel('Ø§Ù„Ù‚ÙŠÙ…Ø©')
    axes[0, 1].grid(axis='y', alpha=0.3)
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    for bar in bars:
        height = bar.get_height()
        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.3f}', ha='center', va='bottom', fontweight='bold')
    
    # 3. ROC Curve
    if y_proba is not None:
        fpr, tpr, _ = roc_curve(y_true, y_proba[:, 1])
        roc_auc = auc(fpr, tpr)
        
        axes[1, 0].plot(fpr, tpr, color='darkorange', lw=2, 
                       label=f'ROC curve (AUC = {roc_auc:.2f})')
        axes[1, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                       label='Random')
        axes[1, 0].set_xlim([0.0, 1.0])
        axes[1, 0].set_ylim([0.0, 1.05])
        axes[1, 0].set_xlabel('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„Ø®Ø§Ø·Ø¦Ø©')
        axes[1, 0].set_ylabel('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©')
        axes[1, 0].set_title('Ù…Ù†Ø­Ù†Ù‰ ROC', fontweight='bold')
        axes[1, 0].legend(loc="lower right")
        axes[1, 0].grid(alpha=0.3)
    
    # 4. Class Distribution
    unique, counts = np.unique(y_true, return_counts=True)
    axes[1, 1].pie(counts, labels=[CLASS_NAMES_AR[i] for i in unique], 
                   autopct='%1.1f%%', startangle=90,
                   colors=['#28a745', '#dc3545'])
    axes[1, 1].set_title('ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª', fontweight='bold')
    
    plt.tight_layout()
    return fig

def print_detailed_report(y_true, y_pred, y_proba, model_name):
    """Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± ØªÙØµÙŠÙ„ÙŠ"""
    print("\n" + "="*60)
    print(f"ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙØµÙŠÙ„ÙŠ - {model_name}")
    print("="*60)
    
    # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')
    
    print(f"\nâœ… Ø§Ù„Ø¯Ù‚Ø© (Accuracy):       {accuracy*100:.2f}%")
    print(f"ğŸ¯ Ø§Ù„Ø¯Ù‚Ø© (Precision):      {precision*100:.2f}%")
    print(f"ğŸ“ˆ Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ (Recall):     {recall*100:.2f}%")
    print(f"âš–ï¸  F1-Score:              {f1*100:.2f}%")
    
    # Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nğŸ“‹ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³:")
    print(f"   {'':12} {'Ø³Ù„ÙŠÙ…Ø©':>10} {'Ø³Ø±Ø·Ø§Ù†':>10}")
    print(f"   {'Ø³Ù„ÙŠÙ…Ø©':12} {cm[0,0]:10d} {cm[0,1]:10d}")
    print(f"   {'Ø³Ø±Ø·Ø§Ù†':12} {cm[1,0]:10d} {cm[1,1]:10d}")
    
    # ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ
    print(f"\nğŸ“ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:")
    report = classification_report(y_true, y_pred, 
                                   target_names=CLASS_NAMES_AR,
                                   digits=3)
    print(report)
    
    # ROC AUC
    if y_proba is not None:
        from sklearn.metrics import roc_auc_score
        try:
            roc_auc = roc_auc_score(y_true, y_proba[:, 1])
            print(f"\nğŸ” ROC AUC Score:          {roc_auc:.4f}")
        except:
            pass

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("\n" + "="*60)
    print("ğŸ« Ù†Ø¸Ø§Ù… Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø±Ø¦Ø©")
    print("="*60)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    images_path, true_labels, _ = load_test_data()
    
    if images_path is None or len(images_path) == 0:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±!")
        return
    
    # Ø§Ø®ØªØ¨Ø§Ø± PyTorch
    if PYTORCH_AVAILABLE and os.path.exists(MODEL_PATH):
        predictions_pt, probabilities_pt = test_pytorch_model(images_path, true_labels)
        
        if predictions_pt is not None:
            print_detailed_report(true_labels, predictions_pt, probabilities_pt, "PyTorch CNN")
            fig = plot_metrics(true_labels, predictions_pt, probabilities_pt, "PyTorch CNN")
            plt.savefig("pytorch_evaluation.png", dpi=300, bbox_inches='tight')
            print("\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ÙÙŠ pytorch_evaluation.png")
            plt.show()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Scikit-learn
    model_path = MODEL_PATH_SKLEARN if os.path.exists(MODEL_PATH_SKLEARN) else "lung_model.pkl"
    if SKLEARN_AVAILABLE and os.path.exists(model_path):
        predictions_sk, probabilities_sk = test_sklearn_model(images_path, true_labels)
        
        if predictions_sk is not None:
            print_detailed_report(true_labels, predictions_sk, probabilities_sk, "Scikit-learn")
            fig = plot_metrics(true_labels, predictions_sk, probabilities_sk, "Scikit-learn")
            plt.savefig("sklearn_evaluation.png", dpi=300, bbox_inches='tight')
            print("\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ÙÙŠ sklearn_evaluation.png")
            plt.show()
    
    print("\n" + "="*60)
    print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")
    print("="*60 + "\n")

if __name__ == "__main__":
    main()
