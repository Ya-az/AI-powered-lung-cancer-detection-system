import streamlit as st
import torch
import torch.nn as nn
from PIL import Image
import numpy as np
from torchvision import transforms
import os

# ===== ØªÙƒÙˆÙŠÙ† Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(
    page_title="ØªØµÙ†ÙŠÙ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø±Ø¦Ø©",
    page_icon="ğŸ«",
    layout="centered",
    initial_sidebar_state="expanded"
)

# CSS Ù…Ø®ØµØµ
st.markdown("""
    <style>
    .main {
        background-color: #f5f5f5;
    }
    .stTitle {
        color: #2c3e50;
        text-align: center;
    }
    .result-box {
        padding: 20px;
        border-radius: 10px;
        font-size: 18px;
        font-weight: bold;
        text-align: center;
    }
    .healthy {
        background-color: #d4edda;
        color: #155724;
        border: 2px solid #28a745;
    }
    .cancer {
        background-color: #f8d7da;
        color: #721c24;
        border: 2px solid #f5c6cb;
    }
    </style>
""", unsafe_allow_html=True)

# ===== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ =====
MODEL_PATH = "lung_model.pth"

class LungClassifier(nn.Module):
    def __init__(self):
        super(LungClassifier, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(256 * 14 * 14, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 2)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

@st.cache_resource
def load_model():
    device = torch.device("cpu")
    model = LungClassifier().to(device)
    
    if os.path.exists(MODEL_PATH):
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        model.eval()
        return model, True
    else:
        return model, False

# ===== Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© =====
st.title("ğŸ« ØªØ­Ù„ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø±Ø¦Ø©")
st.subheader("Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø±Ø¦Ø©")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model, model_loaded = load_model()

if not model_loaded:
    st.error("âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `train_model.py`")
    st.info("Ø§Ù„Ø®Ø·ÙˆØ§Øª:")
    st.write("""
    1. Ø¶Ø¹ ØµÙˆØ± Ø§Ù„Ø±Ø¦Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ `img/`
    2. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª: 
       - `normal_*.jpg` Ù„Ù„ØµÙˆØ± Ø§Ù„Ø³Ù„ÙŠÙ…Ø©
       - `cancer_*.jpg` Ù„ØµÙˆØ± Ø§Ù„Ø³Ø±Ø·Ø§Ù†
    3. Ø´ØºÙ‘Ù„: `python train_model.py`
    """)
else:
    st.success("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
    
    # ===== ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±ÙØ¹ =====
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø£Ø´Ø¹Ø© Ù„Ù„Ø±Ø¦Ø©",
            type=["jpg", "jpeg", "png", "bmp"]
        )
    
    if uploaded_file is not None:
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
        image = Image.open(uploaded_file).convert('RGB')
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", use_column_width=True)
        
        # ===== Ø§Ù„ØªÙ†Ø¨Ø¤ =====
        device = torch.device("cpu")
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        img_tensor = transform(image).unsqueeze(0).to(device)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        with torch.no_grad():
            outputs = model(img_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = probabilities[0][predicted_class].item() * 100
        
        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        class_names = ["Ø³Ù„ÙŠÙ…Ø© âœ“", "Ø³Ø±Ø·Ø§Ù† âœ—"]
        
        with col2:
            st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            
            if predicted_class == 0:
                st.markdown(
                    f"""
                    <div class="result-box healthy">
                    Ø§Ù„Ø±Ø¦Ø©: <b>Ø³Ù„ÙŠÙ…Ø©</b><br/>
                    Ø§Ù„Ø«Ù‚Ø©: {confidence:.1f}%
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.success(f"ğŸ˜Š Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ - Ø§Ù„Ø±Ø¦Ø© Ø³Ù„ÙŠÙ…Ø© Ø¨Ù†Ø³Ø¨Ø© Ø«Ù‚Ø© {confidence:.1f}%")
            else:
                st.markdown(
                    f"""
                    <div class="result-box cancer">
                    Ø§Ù„Ø±Ø¦Ø©: <b>Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø³Ø±Ø·Ø§Ù†</b><br/>
                    Ø§Ù„Ø«Ù‚Ø©: {confidence:.1f}%
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.error(f"âš ï¸ ØªØ­Ø°ÙŠØ± - Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø³Ø±Ø·Ø§Ù† Ø¨Ù†Ø³Ø¨Ø© Ø«Ù‚Ø© {confidence:.1f}%")
        
        # ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Ø§Ù„Ø±Ø¦Ø© Ø§Ù„Ø³Ù„ÙŠÙ…Ø©", f"{probabilities[0][0].item()*100:.1f}%")
        
        with col2:
            st.metric("Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø³Ø±Ø·Ø§Ù†", f"{probabilities[0][1].item()*100:.1f}%")
        
        # ØªØ­Ø°ÙŠØ± Ø·Ø¨ÙŠ
        st.info(
            "âš ï¸ **ØªØ­Ø°ÙŠØ±**: Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙÙ‚Ø·. "
            "Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„ÙŠÙ‡ Ù„Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„ÙØ¹Ù„ÙŠ. "
            "ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ¨ Ù…ØªØ®ØµØµ Ù„Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø¯Ù‚ÙŠÙ‚."
        )
    
    else:
        st.info("ğŸ‘ˆ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ø´Ø¹Ø© Ù„Ù„Ø¨Ø¯Ø¡")
        
        st.markdown("---")
        st.markdown("### â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")
        st.write("""
        - ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ØµÙˆØ± Ø£Ø´Ø¹Ø© Ø³ÙŠÙ†ÙŠØ© Ù„Ù„Ø±Ø¦Ø©
        - ÙŠØµÙ†Ù Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰: **Ø³Ù„ÙŠÙ…Ø©** Ø£Ùˆ **Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø³Ø±Ø·Ø§Ù†**
        - Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """)

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
st.sidebar.markdown("### âš™ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
st.sidebar.write("""
- **Ø§Ù„Ù†ÙˆØ¹**: CNN (Convolutional Neural Network)
- **Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„**: 224Ã—224 Ø¨ÙƒØ³Ù„
- **Ø§Ù„ÙØ¦Ø§Øª**: 2 (Ø³Ù„ÙŠÙ…Ø© / Ø³Ø±Ø·Ø§Ù†)
- **Ø§Ù„Ø¥Ø·Ø§Ø±**: PyTorch + Streamlit
""")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“š Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª")
st.sidebar.write("""
1. Ø±ÙÙ‘Ø¹ ØµÙˆØ±Ø© Ø£Ø´Ø¹Ø© Ø³ÙŠÙ†ÙŠØ© Ù„Ù„Ø±Ø¦Ø©
2. Ø³ÙŠÙ†ØªØ¸Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
3. Ø³ØªØ¸Ù‡Ø± Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ø¹ Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©
4. Ø§Ø³ØªØ´Ø± Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø¯Ø§Ø¦Ù…Ø§Ù‹
""")
